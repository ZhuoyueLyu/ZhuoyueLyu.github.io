<html>
<script>
    (function(){

var addEvent = function (el, type, fn) {
  if (el.addEventListener)
    el.addEventListener(type, fn, false);
      else
          el.attachEvent('on'+type, fn);
};

var extend = function(obj,ext){
  for(var key in ext)
    if(ext.hasOwnProperty(key))
      obj[key] = ext[key];
  return obj;
};

window.fitText = function (el, kompressor, options) {

  var settings = extend({
    'minFontSize' : -1/0,
    'maxFontSize' : 1/0
  },options);

  var fit = function (el) {
    var compressor = kompressor || 1;

    var resizer = function () {
      el.style.fontSize = Math.max(Math.min(el.clientWidth / (compressor*10), parseFloat(settings.maxFontSize)), parseFloat(settings.minFontSize)) + 'px';
    };

    // Call once to set.
    resizer();

    // Bind events
    // If you have any js library which support Events, replace this part
    // and remove addEvent function (or use original jQuery version)
    addEvent(window, 'resize', resizer);
    addEvent(window, 'orientationchange', resizer);
  };

  if (el.length)
    for(var i=0; i<el.length; i++)
      fit(el[i]);
  else
    fit(el);

  // return set of elements
  return el;
};
})();

// this is to make sure our text is responsive on different sized screens
window.fitText( document.getElementsByClassName("subTitle"), 1.5);
</script>
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <h3nk rel="stylesheet" href="./index_files/w3.css">
        <style>
            body,
            h1,
            h2,
            h3,
            h4,
            h5 {
                font-family: 'Rajdhani', serif
            }
        </style>
</head>

<body>
    <div class=" w3-container w3-white w3-center w3-text-black w3-animate-opacity w3-padding-32" style="max-height:100%">
        <br><br><br>
        <div class="w3-content w3-justify " style="max-width:85%">
            <style>
                .video_wrapper {
                    position: relative;
                    padding-bottom: 53.4375%;
                    max-width: 95%;
                }

                .iframe {
                    position: absolute;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 100%;
                }
                .subTitle{
                    font-size: 2;
                    text-overflow: ellipsis;
                    line-height:0;
                }
            </style>
            <div id="sensing-AI">
                <!-- Title row -->
                <div class="w3-row">
                    <span class="w3-tag w3-blue">Author</span>
                    <h2 class="w3-wrap" style="font-size:2.5rem"><strong>Sensing AI</strong><span class="w3-opacity" style="font-size:1.90rem "> | In Progress</span></h2>
                    <h2 class="w3-wrap" style="font-size:1.5rem"><strong>Zhuoyue Lyu</strong><span class="w3-opacity" style="font-size:1.2rem "> | Aiming at International Computer Music Conference (ICMC) 2021</span></h2>
                </div>
                <!-- video row -->
                <div class="w3-row">
                    <div class="w3-twothird" style="margin-top: 1rem;">
                        <div class="video_wrapper w3-card-4 ">
                            <iframe class="iframe " src="https://www.youtube.com/embed/P0ebqCZXnow" frameborder="0 " allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture " allowfullscreen></iframe>
                        </div>
                    </div>
                    <div class="w3-third" style="margin-top: 1rem;">
                        <a style=" font-family: 'Open Sans', sans-serif; font-size:1.25rem; max-width: 85%; pointer-events: none;">
                            <p>To provide people with auditory and visual intuition about AI, I sonified a neural network by mapping loss and accuracy to oscillators' frequencies and visualized it using an interactive force-directed graph in Virtual Reality (VR)</p>
                        </a>
                    </div>
                </div>
            </div>
            <div id="terminator-hands"style="margin-top: 7rem;">
              <!-- Title row -->
              <div class="w3-row">
                  <h2 class="w3-wrap" style="font-size:2.5rem"><strong>Terminator Hands</strong><span class="w3-opacity" style="font-size:1.90rem "> | In Progress</span></h2>
                  <h2 class="w3-wrap" style="font-size:1.5rem">Fengyuan Zhu, <strong>Zhuoyue Lyu</strong>, Tovi Grossman<span class="w3-opacity" style="font-size:1.2rem "> | Aiming at ACM Symposium on User Interface Software and Technology (UIST) 2021</span></h2>
              </div>
              <!-- video row -->
              <div class="w3-row">
                  <div class="w3-twothird" style="margin-top: 1rem;">
                      <div class="video_wrapper w3-card-4 ">
                          <iframe class="iframe " src="https://www.youtube.com/embed/9NTq-GkOQF0" frameborder="0 " allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture " allowfullscreen></iframe>
                      </div>
                  </div>
                  <div class="w3-third" style="margin-top: 1rem;">
                      <a style=" font-family: 'Open Sans', sans-serif; font-size:1.25rem; max-width: 85%; pointer-events: none;">
                          <p>Designing different virtual hands to explore the impact of hands morphing on human-object interactions in VR.</p>
                          <p>I developed the following types of morphying hands in VR:</p>
                          <p>1. Scalable hands<br>
                             2. Auto-scable hands<br>
                             3. Duplicable hands<br>
                             4. Movable hands </p>
                      </a>
                  </div>
              </div>
              <div id="voiding-the-touch"style="margin-top: 7rem;">
                <!-- Title row -->
                <div class="w3-row">
                    <h2 class="w3-wrap" style="font-size:2.5rem"><strong>Voiding the Touch</strong><span class="w3-opacity" style="font-size:1.90rem "> | In Progress</span></h2>
                    <h2 class="w3-wrap" style="font-size:1.5rem">Fengyuan Zhu, <strong>Zhuoyue Lyu</strong>, Tovi Grossman<span class="w3-opacity" style="font-size:1.2rem "> | Aiming at Conference on Human Factors in Computing Systems (CHI) 2022</span></h2>
                </div>
                <!-- video row -->
                <div class="w3-row" style=" max-width: 75%">
                    <div style="margin-top: 1rem;">
                        <img src="./cs_files/voiding-unclear.png" alt="Me" class="w3-image w3-card-2 " width="100%">
                        <div style="margin-top: 1rem;">
                            <a style=" font-family: 'Open Sans', sans-serif; font-size:1.25rem; pointer-events: none;">
                                <p>Understanding performance of touch events on a physical device under different input modalities in virtual environments by analyzing time and accuracy data from user studies. The image above is blurred on purpose, since this work has not published yet.</p>
                            </a>
                        </div>
                    </div>
                </div>
          </div>
            <footer class="w3-container w3-padding-1 w3-center w3-opacity w3-white ">
                <p class="w3-medium ">Copyright Â© 2021 Zhuoyue Lyu. All rights reserved.
                    <a href="mailto:zhuoyue.lyu@mail.utoronto.ca " target="_top "></p>
            </footer>

</body>

</html>